{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c25dc8-18db-4931-8d8f-8a833af4c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from torch.utils.data import TensorDataset\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix\n",
    "from utils.function import prep_data\n",
    "from models.de_OPPO import DAE\n",
    "from models.activity_recognition import *\n",
    "# from models.activity_recognition_OPPO import get_eval_model\n",
    "from models.dis_z import DIS_Z\n",
    "import copy\n",
    "import sklearn.metrics as metrics\n",
    "import os\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d944f1-784f-4210-9546-deaf048b6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.root = '../data'\n",
    "        self.batchSize = 64\n",
    "        self.maxEpochs = 100\n",
    "        self.nz = 200\n",
    "        self.lr = 1e-4\n",
    "        self.fSize = 64\n",
    "        self.outDir = 'data/experiments/DE_OPPO1'\n",
    "        self.commit = 'eval'\n",
    "        self.alpha = 1.0\n",
    "        # self.sigma = 0.35\n",
    "        self.M = 5\n",
    "        self.loss = 'MSE' #'BCE'\n",
    "        self.loadDAE = False\n",
    "        self.loadSVM = False    \n",
    "        self.load_DAE_from = None\n",
    "        self.evalMode = False\n",
    "        self.comment = ''\n",
    "        self.momentum = 0.1\n",
    "        self.c = 0.01\n",
    "        self.svmLR = 1e-4\n",
    "        self.Ntest = 100\n",
    "        self.gpuNo = 2\n",
    "        self.multimodalZ = False\n",
    "        self.window_len = 512\n",
    "        self.stride_len = 20\n",
    "        self.act_list = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "        self.imSize = 64\n",
    "        # self.sigma = [60, 80]\n",
    "        self.sigma=0.05\n",
    "        # self.sigma = [6, 10]\n",
    "        self.cuda_id = 2\n",
    "        self.random_seed = 2\n",
    "        self.train_split = 0.8\n",
    "\n",
    "        #self.corr= 'ZeroMask' # options: Gaussian, ZeroMask, ConsecutiveZeros\n",
    "        # if self.corr == 'ConsecutiveZeros':\n",
    "        #     self.sigma = [40, 80] # [lambda_corr, lambda_norm]\n",
    "\n",
    "        # path for corruption \"consecutive interval\"sigma [60,80]\n",
    "        self.dae_model_loc = \"data/experiments/DAE_EVAL_Noise/Ex_12\" \n",
    "\n",
    "        self.ar_model_loc = \"data/opportunity_ConvAttn.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf4fc7a-974d-424c-8c05-567b447e020b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Current GPU ID: 0\n"
     ]
    }
   ],
   "source": [
    "gpu_id = 3\n",
    "\n",
    "if gpu_id>=0:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    cuda_id = \"cuda:\" + str(0)  # cuda:2\n",
    "\n",
    "device = torch.device(cuda_id if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "    print(\"Current GPU ID:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff755101-ccb9-44fb-9b83-7011f4c7ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dis(args, dae, multimodalZ):\n",
    "    if not multimodalZ:\n",
    "        print('\\n ** USING NORMAL PRIOR **')\n",
    "        prior = dae.norm_prior\n",
    "        NZ = args.nz\n",
    "    else:\n",
    "        print('\\n ** USING MULTIMODAL PRIOR **')\n",
    "        prior = dae.multi_prior\n",
    "        NZ = 2\n",
    "    dis = DIS_Z(nz=NZ, prior=prior)\n",
    "\n",
    "    return dis, NZ\n",
    "\n",
    "\n",
    "def analysis(args, dae, testDataset, X, num_classes):\n",
    "    # Prepare testdata set, drop the last incomplete batch\n",
    "    test_x = torch.zeros(len(testDataset), X.shape[1], X.shape[2], X.shape[3])\n",
    "    test_labels = torch.zeros(len(testDataset), num_classes)\n",
    "    for test_id in range(len(testDataset)):\n",
    "        test_labels[test_id] = testDataset[test_id][1]\n",
    "        test_x[test_id] = testDataset[test_id][0]\n",
    "    print(test_x.shape)\n",
    "\n",
    "    # Corrupt dataset\n",
    "    corr_test_x = dae.corrupt(test_x)\n",
    "    \n",
    "    mean_fill_test = interpolation_meanfilling(corr_test_x)\n",
    "    linear_interp_test = linear_interpolation(corr_test_x)\n",
    "# recon_test -> synthesize the entire dataset\n",
    "    z = dae.encode(corr_test_x)\n",
    "    recon_test = dae.decode(z)\n",
    "\n",
    "    # breakpoint()\n",
    "# reconstruct filling testset (fill missing values only, not valid for noisy data)\n",
    "    recon_fill_test = copy.deepcopy(corr_test_x).detach().cpu().numpy()\n",
    "    np.copyto(recon_fill_test, recon_test.detach().numpy(), where = recon_fill_test==0)\n",
    "    recon_fill_test = torch.from_numpy(recon_fill_test)\n",
    "\n",
    "    # Reconstruct testset\n",
    "    # corr_test_dataset = TensorDataset(outputs.permute(0, 2, 1))\n",
    "    #recon_test = torch.from_numpy(recon_test)#.permute(1, 2, 0)\n",
    "    \n",
    "    # test_x = test_x.reshape(test_x.shape[0],test_x.shape[2],test_x.shape[3])\n",
    "    # corr_test_x = corr_test_x.reshape(corr_test_x.shape[0],corr_test_x.shape[2],corr_test_x.shape[3])\n",
    "    # recon_test = recon_test.reshape(recon_test.shape[0],recon_test.shape[2],recon_test.shape[3])\n",
    "    # recon_fill_test = recon_fill_test.reshape(recon_fill_test.shape[0],recon_fill_test.shape[2],recon_fill_test.shape[3])\n",
    "    # mean_fill_test = mean_fill_test.reshape(mean_fill_test.shape[0],mean_fill_test.shape[2],mean_fill_test.shape[3])\n",
    "    # test_x = test_x.permute(0,1,3,2)\n",
    "    # corr_test_x = corr_test_x.permute(0,1,3,2)\n",
    "    # recon_test = recon_test.permute(0,1,3,2)\n",
    "    # recon_fill_test = recon_fill_test.permute(0,1,3,2)\n",
    "    # mean_fill_test = mean_fill_test.permute(0,1,3,2)\n",
    "\n",
    "\n",
    "    raw_test_dataset = TensorDataset(test_x, test_labels)\n",
    "    corr_test_dataset = TensorDataset(corr_test_x, test_labels)\n",
    "    recon_test_dataset = TensorDataset(recon_test, test_labels)\n",
    "    recon_fill_test_dataset = TensorDataset(recon_fill_test, test_labels)\n",
    "    mean_fill_test_dataset = TensorDataset(mean_fill_test, test_labels)\n",
    "    linear_interp_test_dataset = TensorDataset(linear_interp_test, test_labels)\n",
    "\n",
    "    return test_x, corr_test_x, recon_test, recon_fill_test, mean_fill_test, linear_interp_test, raw_test_dataset, corr_test_dataset, recon_test_dataset, recon_fill_test_dataset, mean_fill_test_dataset,linear_interp_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c15e3fec-68d3-4e72-b1a9-fa99f1d45724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sliding_window import sliding_window\n",
    "import pickle as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9dde417-c06c-44aa-90a2-c258fe96c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Sensor Channels used in the OPPORTUNITY dataset.\n",
    "NB_SENSOR_CHANNELS = 113\n",
    "\n",
    "# Number of classes in which data is classified (or to be classified).\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# Length of the sliding window used to segmenting the time-series-data.\n",
    "SLIDING_WINDOW_LENGTH = 24\n",
    "\n",
    "# Steps of the sliding window used in segmenting the data.\n",
    "SLIDING_WINDOW_STEP = 12\n",
    "\n",
    "act_labels_txt = ['std', 'wlk', 'sit', 'lie', 'null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae52c086-55ac-4bb0-bfef-72528351c25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      " ..from file ../../../../../data/oppChallenge_gestures.data\n",
      " ..reading instances: train (557963, 113), test (118750, 113)\n",
      " ..after sliding window (testing): inputs (9894, 24, 113), targets (9894,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9894, 1, 113, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = open(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading Data...\")\n",
    "X_train, y_train, X_test, y_test = load_dataset('../../../../../data/oppChallenge_gestures.data')\n",
    "\n",
    "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
    "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))\n",
    "X_test = np.transpose(X_test, (0, 2, 1))\n",
    "X_test= X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2]) # convert list to numpy array\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aba6abe2-66d3-4b56-aac9-c1ac54f23640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ..after sliding window (training): inputs (46495, 24, 113), targets (46495,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(46495, 1, 113, 24)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "print(\" ..after sliding window (training): inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
    "X_train = X_train.reshape((-1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))\n",
    "X_train = np.transpose(X_train, (0, 2, 1))\n",
    "X_train= X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2]) # convert list to numpy array\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad952738-970d-4d03-b9fa-b38690f77f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac638067-7240-4159-b37b-c2532899ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation_meanfilling(corr_test_x):\n",
    "    mean_fill_test = copy.deepcopy(corr_test_x).detach().cpu().numpy()\n",
    "    for i in range(mean_fill_test.shape[0]):\n",
    "        for j in range(mean_fill_test.shape[2]):\n",
    "            if np.count_nonzero(mean_fill_test[i,:,j,:]) == 0:  \n",
    "                ch_mean = 0\n",
    "            else:\n",
    "             #ch_mean = np.sum(mean_fill_test[i][0][j]) / np.count_nonzero(mean_fill_test[i][0][j])\n",
    "                ch_mean = np.sum(mean_fill_test[i,:,j,:]) / np.count_nonzero(mean_fill_test[i,:,j,:])\n",
    "                mean_fill_test[i,:,j,:][mean_fill_test[i,:,j,:] == 0] = ch_mean\n",
    "    mean_fill_test = torch.from_numpy(mean_fill_test)\n",
    "    return mean_fill_test\n",
    "\n",
    "def linear_interpolation(corr_test_x):\n",
    "    linear_interp_test = copy.deepcopy(corr_test_x).detach().cpu().numpy()\n",
    "    # corr_text_x shape is 18944, 1, 27, 171\n",
    "    # expected shape 18944, 171, 27\n",
    "    # linear_interp_test = linear_interp_test.reshape(-1, 171,27)\n",
    "    linear_interp_test = linear_interp_test.reshape(-1, linear_interp_test.shape[3],linear_interp_test.shape[2])\n",
    "    for i in range(linear_interp_test.shape[0]):\n",
    "        for j in range(linear_interp_test.shape[2]):\n",
    "            if np.count_nonzero(linear_interp_test[i,:,j]) == 0: # when all data points in this channel are missing\n",
    "                linear_interp_test[i, :, j] = 0.0\n",
    "            else:\n",
    "                idxs = np.arange(linear_interp_test.shape[1]) # indexes of all the samples\n",
    "                zero_filter = linear_interp_test[i,:,j] == 0 # index filter for zero values\n",
    "                zero_idxs = idxs[zero_filter] # indexes for zero values\n",
    "                non_zero_idxs = idxs[~zero_filter] # xp, indexes for non-zero values\n",
    "                non_zero_vals = linear_interp_test[i, ~zero_filter,j] # fp, non-zero values\n",
    "                interp_vals = np.interp(zero_idxs, non_zero_idxs, non_zero_vals) # interpolated values\n",
    "                linear_interp_test[i,zero_idxs,j] = interp_vals # fill interpolated values to the corrupted signal\n",
    "    linear_interp_test = torch.from_numpy(linear_interp_test)\n",
    "    linear_interp_test = torch.reshape(linear_interp_test, (-1, 1, linear_interp_test.shape[2], linear_interp_test.shape[1]))\n",
    "    return linear_interp_test\n",
    "\n",
    "\n",
    "def evaluate_rmse(corr_test_x, recon_test, recon_fill_test,mean_fill_test,linear_interp_test,test_x):\n",
    "    corr_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1).cpu().detach().numpy(), corr_test_x.reshape(corr_test_x.shape[0],-1).cpu().detach().numpy(), squared=False)\n",
    "    print('Corr RMSE:\\n' + str(corr_rms))\n",
    "\n",
    "    recon_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1).cpu().detach().numpy(), recon_test.reshape(recon_test.shape[0],-1).cpu().detach().numpy(), squared=False)\n",
    "    print('Recon RMSE:\\n' + str(recon_rms))\n",
    "\n",
    "    recon_fill_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1).cpu().detach().numpy(), recon_fill_test.reshape(recon_fill_test.shape[0],-1).cpu().detach().numpy(), squared=False)\n",
    "    print('Recon fill RMSE:\\n' + str(recon_fill_rms))\n",
    "\n",
    "    mean_fill_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1).cpu().detach().numpy(), mean_fill_test.reshape(mean_fill_test.shape[0],-1).cpu().detach().numpy(), squared=False)\n",
    "    print('Mean Fill RMSE:\\n' + str(mean_fill_rms))\n",
    "    \n",
    "    linear_interp_rms = mean_squared_error(test_x.reshape(test_x.shape[0],-1), linear_interp_test.reshape(linear_interp_test.shape[0],-1).cpu().detach().numpy(), squared=False)\n",
    "    print('Linear Interpolation RMSE:\\n' + str(linear_interp_rms))\n",
    "    return \n",
    "#def plot(test_x, corr_test_x, recon_test)\n",
    "\n",
    "def plot(test_x, corr_test_x, recon_test, recon_fill_test,mean_fill_test, linear_interp_test):\n",
    "    plt.imshow(test_x[0][0].detach())\n",
    "    plt.title('Raw Data')\n",
    "   # plt.subplot(4,1,1)\n",
    "    plt.savefig(join(args.dae_model_loc, 'raw.png'))\n",
    "\n",
    "    plt.imshow(corr_test_x[0][0].detach())\n",
    "    plt.title('Corrupted')\n",
    "   # plt.subplot(4,1,2)\n",
    "    plt.savefig(join(args.dae_model_loc, 'corr.png'))\n",
    "\n",
    "    plt.imshow(recon_test[0][0].detach())\n",
    "    plt.title('Reconstructed')\n",
    "   # plt.subplot(4,1,3)\n",
    "    plt.savefig(join(args.dae_model_loc, 'reconstructed.png'))\n",
    "\n",
    "    plt.imshow(recon_fill_test[0][0].detach())\n",
    "    plt.title('Reconstructed fill')\n",
    "   # plt.subplot(4,1,3)\n",
    "    plt.savefig(join(args.dae_model_loc, 'rec_fill.png'))\n",
    "\n",
    "    plt.imshow(mean_fill_test[0][0].detach())\n",
    "    plt.title('Mean Fill')\n",
    "   # plt.subplot(4,1,4)\n",
    "    plt.savefig(join(args.dae_model_loc, 'mean.png'))\n",
    "    \n",
    "    plt.imshow(linear_interp_test[0][0].detach())\n",
    "    plt.title('Linear Interp')\n",
    "   # plt.subplot(4,1,4)\n",
    "    plt.savefig(join(args.dae_model_loc, 'linear.png'))\n",
    "    \n",
    "    return\n",
    "\n",
    "def test_dae(args, path, trainLoader, testLoader):\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_activity_recognition(args, path, trainLoader, testLoader):\n",
    "    pass\n",
    "\n",
    "\n",
    "def calculate_combined_accuracy(args, test_loader, sigma):\n",
    "    # device = torch.device(args.cuda_id if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    args.n_sensor_channels = 113\n",
    "    args.len_seq = 24\n",
    "    args.num_classes=5\n",
    "    ar = get_eval_model(n_sensor_channels=args.n_sensor_channels, len_seq=args.len_seq, num_classes=args.num_classes, model_path=args.ar_model_loc) #n_sensor_channels, len_seq, num_classes, model_path\n",
    "    ar = ar.to(device)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_true = []\n",
    "    total_pred = []\n",
    "\n",
    "    with torch.no_grad():   \n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)  \n",
    "            # print(images.shape)\n",
    "            \n",
    "            outputs = ar(images)\n",
    "\n",
    "            # _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = torch.argmax(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "            \n",
    "            total_pred = total_pred + predicted.cpu().numpy().tolist()\n",
    "            total_true = total_true + (torch.argmax(labels, dim=1).cpu().numpy().tolist())\n",
    "            \n",
    "    print(f'Test Accuracy: \\n{100.0 * correct / total} ')\n",
    "    \n",
    "    # print(\" | \".join(act_labels_txt))\n",
    "    conf_mat = confusion_matrix(y_true = total_true, y_pred = total_pred)\n",
    "    conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "    print(np.array(conf_mat).round(3) * 100)  \n",
    "    f1_score = metrics.f1_score(y_true = total_true, y_pred = total_pred, average='weighted')\n",
    "    print('F1 score:\\n', f1_score)\n",
    "    print('')\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f846e27-c581-4188-a91f-50a5313dc137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading params...\n",
      "torch.Size([9856, 1, 113, 24])\n",
      "Raw testset:\n",
      "Test Accuracy: \n",
      "89.21469155844156 \n",
      "[[79.   4.9 13.8  1.4  0.8]\n",
      " [ 0.8 93.8  4.3  1.1  0. ]\n",
      " [ 2.9 14.3 82.4  0.4  0. ]\n",
      " [ 0.6  0.6  0.  98.6  0.1]\n",
      " [ 1.5  0.   0.2  3.  95.2]]\n",
      "F1 score:\n",
      " 0.8912435729751317\n",
      "\n",
      "Corrupted testset:\n",
      "Test Accuracy: \n",
      "84.93303571428571 \n",
      "[[75.9  2.3 19.1  2.   0.6]\n",
      " [ 1.1 79.  18.6  1.2  0. ]\n",
      " [ 3.3  9.2 87.1  0.3  0. ]\n",
      " [ 0.8  0.5  0.  98.5  0.1]\n",
      " [ 3.   0.   0.6  2.6 93.7]]\n",
      "F1 score:\n",
      " 0.8515978830890847\n",
      "\n",
      "Reconstructed testset:\n",
      "Test Accuracy: \n",
      "88.58563311688312 \n",
      "[[78.7  5.  14.1  1.4  0.7]\n",
      " [ 0.8 94.2  3.5  1.5  0. ]\n",
      " [ 3.3 17.  79.3  0.4  0. ]\n",
      " [ 0.7  0.6  0.  98.6  0.1]\n",
      " [ 1.1  0.   0.2  2.8 95.9]]\n",
      "F1 score:\n",
      " 0.8845829896895254\n",
      "\n",
      "Reconstructed fill testset:\n",
      "Test Accuracy: \n",
      "84.93303571428571 \n",
      "[[75.9  2.3 19.1  2.   0.6]\n",
      " [ 1.1 79.  18.6  1.2  0. ]\n",
      " [ 3.3  9.2 87.1  0.3  0. ]\n",
      " [ 0.8  0.5  0.  98.5  0.1]\n",
      " [ 3.   0.   0.6  2.6 93.7]]\n",
      "F1 score:\n",
      " 0.8515978830890847\n",
      "\n",
      "Mean Fill testset\n",
      "Test Accuracy: \n",
      "84.93303571428571 \n",
      "[[75.9  2.3 19.1  2.   0.6]\n",
      " [ 1.1 79.  18.6  1.2  0. ]\n",
      " [ 3.3  9.2 87.1  0.3  0. ]\n",
      " [ 0.8  0.5  0.  98.5  0.1]\n",
      " [ 3.   0.   0.6  2.6 93.7]]\n",
      "F1 score:\n",
      " 0.8515978830890847\n",
      "\n",
      "Linear Interpolation testset:\n",
      "Test Accuracy: \n",
      "84.93303571428571 \n",
      "[[75.9  2.3 19.1  2.   0.6]\n",
      " [ 1.1 79.  18.6  1.2  0. ]\n",
      " [ 3.3  9.2 87.1  0.3  0. ]\n",
      " [ 0.8  0.5  0.  98.5  0.1]\n",
      " [ 3.   0.   0.6  2.6 93.7]]\n",
      "F1 score:\n",
      " 0.8515978830890847\n",
      "\n",
      "Corr RMSE:\n",
      "0.05001875\n",
      "Recon RMSE:\n",
      "0.02331595\n",
      "Recon fill RMSE:\n",
      "0.05001875\n",
      "Mean Fill RMSE:\n",
      "0.05001875\n",
      "Linear Interpolation RMSE:\n",
      "0.05001875\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = Args()\n",
    "    if args.multimodalZ:\n",
    "        args.nz = 2\n",
    "        \n",
    "    args.num_classes = 5\n",
    "    # random.seed(args.random_seed)\n",
    "    # np.random.seed(args.random_seed)\n",
    "    # torch.manual_seed(args.random_seed)\n",
    "\n",
    "    X = torch.from_numpy(X_test[:9856,:,:])\n",
    "    labels = torch.from_numpy(y_test[:9856,:])\n",
    "    # X, labels = prepare_data(args)\n",
    "    # trainDataset, testDataset, trainLoader, testLoader = prepare_dataloaders(args, X, labels)\n",
    "    \n",
    "    testDataset = TensorDataset(X, labels)\n",
    "\n",
    "\n",
    "    testLoader = torch.utils.data.DataLoader(testDataset,\n",
    "        batch_size=args.batchSize, shuffle=False)    \n",
    "    \n",
    "    dae = DAE(nz=args.nz, imSize=args.imSize, fSize=args.fSize, sigma=args.sigma, multimodalZ=args.multimodalZ)\n",
    "    dae.load_params(args.dae_model_loc)\n",
    "    # if dae.useCUDA:\n",
    "    #     torch.cuda.set_device(args.gpuNo)\n",
    "    #     # torch.cuda.set_device(args.gpuNo)\n",
    "    #     dae.cuda()\n",
    "    #     # dis.cuda()\n",
    "\n",
    "    # test_dae(args, dae_path, trainLoader, testLoader)\n",
    "    # test_activity_recognition(args, ar_path, trainLoader, testLoader)\n",
    "\n",
    "    #acc = calculate_combined_accuracy(args, testLoader, sigma=0.5)\n",
    "    test_x, corr_test_x, recon_test, recon_fill_test, mean_fill_test, linear_interp_test, raw_test_dataset, corr_test_dataset, recon_test_dataset, recon_fill_test_dataset, mean_fill_test_dataset, linear_interp_test_dataset = analysis(args, dae, testDataset, X_test, args.num_classes)\n",
    "    # test_x, corr_test_x, recon_test, recon_fill_test, mean_fill_test, raw_test_dataset, corr_test_dataset, recon_test_dataset, recon_fill_test_dataset, mean_fill_test_dataset = analysis(dae, testDataset, labels)\n",
    "    #corr_test_x, test_x, recon_test, raw_test_dataset, corr_test_dataset, recon_test_dataset = analysis(dae, testDataset, labels)\n",
    "\n",
    "    # test_x = test_x.permute(0,1,3,2)\n",
    "    # corr_test_x = corr_test_x.permute(0,1,3,2)\n",
    "    # recon_test = recon_test.permute(0,1,3,2)\n",
    "    # recon_fill_test = recon_fill_test.permute(0,1,3,2)\n",
    "    # mean_fill_test = mean_fill_test.permute(0,1,3,2)\n",
    "    # linear_interp_test = linear_interp_test.permute(0,1,3,2)\n",
    "\n",
    "    print(\"Raw testset:\")\n",
    "    raw_test_loader = torch.utils.data.DataLoader(raw_test_dataset,\n",
    "    batch_size= args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args, raw_test_loader, sigma=args.sigma)\n",
    "\n",
    "    print(\"Corrupted testset:\")\n",
    "    corr_test_loader = torch.utils.data.DataLoader(corr_test_dataset,\n",
    "    batch_size= args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args,corr_test_loader, sigma=args.sigma)\n",
    "\n",
    "    print(\"Reconstructed testset:\")\n",
    "    recon_test_loader = torch.utils.data.DataLoader(recon_test_dataset,\n",
    "    batch_size=args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args,recon_test_loader, sigma=args.sigma)\n",
    "\n",
    "\n",
    "    print(\"Reconstructed fill testset:\")\n",
    "    recon_fill_test_loader = torch.utils.data.DataLoader(recon_fill_test_dataset,\n",
    "    batch_size=args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args,recon_fill_test_loader, sigma=args.sigma)\n",
    "\n",
    "\n",
    "    print(\"Mean Fill testset\")\n",
    "    mean_fill_test_loader = torch.utils.data.DataLoader(mean_fill_test_dataset,\n",
    "    batch_size=args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args,mean_fill_test_loader, sigma=args.sigma)\n",
    "    \n",
    "    print(\"Linear Interpolation testset:\")\n",
    "    linear_interp_test_loader = torch.utils.data.DataLoader(linear_interp_test_dataset,\n",
    "    batch_size=args.batchSize, shuffle=False)\n",
    "    calculate_combined_accuracy(args,linear_interp_test_loader, sigma=args.sigma)\n",
    "\n",
    "    evaluate_rmse(corr_test_x, recon_test,recon_fill_test, mean_fill_test, linear_interp_test,test_x)\n",
    "    plot(test_x, corr_test_x, recon_test,recon_fill_test, mean_fill_test, linear_interp_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38740a4d-b9e5-4f15-8fda-8e1f56a26a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
