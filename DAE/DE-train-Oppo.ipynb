{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7460ff-3b86-4bfd-8ca7-2f476ef7b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from os.path import join\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from torch import optim\n",
    "from torch.nn import BCELoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from models.de_OPPO import DAE\n",
    "from models.dis_z import DIS_Z\n",
    "from models.activity_recognition import *\n",
    "from utils.function import *\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# %pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3315146a-b34e-4de1-92b0-5476dfd7706f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f74b96-c0f1-49f7-80e3-fec97098e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.root = '../data'\n",
    "        self.batchSize = 64\n",
    "        self.maxEpochs = 100\n",
    "        self.nz = 200\n",
    "        self.lr = 1e-4\n",
    "        self.fSize = 64\n",
    "        self.outDir = 'data/experiments/DAE_EVAL_Missing'\n",
    "        self.commit = 'eval'\n",
    "        self.alpha = 1.0\n",
    "        # self.sigma = 0.35\n",
    "        self.M = 5\n",
    "        self.loss = 'MSE' #'BCE'\n",
    "        self.loadDAE = False\n",
    "        self.loadSVM = False    \n",
    "        self.load_DAE_from = None\n",
    "        self.evalMode = False\n",
    "        self.comment = ''\n",
    "        self.momentum = 0.1\n",
    "        self.c = 0.01\n",
    "        self.svmLR = 1e-4\n",
    "        self.Ntest = 100\n",
    "        self.gpuNo = 2\n",
    "        self.cuda_id = 2\n",
    "        self.multimodalZ = False\n",
    "        self.window_len = 512\n",
    "        self.stride_len = 20\n",
    "        self.act_list = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
    "        self.imSize = 64\n",
    "        # self.sigma = [50, 80]\n",
    "        # self.sigma = 0.2\n",
    "        # self.sigma= [0.1, 4, 10]\n",
    "        self.sigma = [8, 10]\n",
    "        # self.sigma = 0.2\n",
    "        self.random_seed = 2\n",
    "        self.train_split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55728fc3-e00f-4aff-9d7d-258842ef04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dis(args, dae, multimodalZ):\n",
    "    if not multimodalZ:\n",
    "        print('\\n ** USING NORMAL PRIOR **')\n",
    "        prior = dae.norm_prior\n",
    "        NZ = args.nz\n",
    "    else:\n",
    "        print('\\n ** USING MULTIMODAL PRIOR **')\n",
    "        prior = dae.multi_prior\n",
    "        NZ = 2\n",
    "    dis = DIS_Z(nz=NZ, prior=prior)\n",
    "\n",
    "    return dis, NZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "158e4416-348e-42be-9ea7-3772bd77de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_data(args):\n",
    "#     X=[]\n",
    "#     user_labels=[]\n",
    "#     act_labels=[]\n",
    "\n",
    "#     # columns for IMU data\n",
    "#     imu_locs = [4,5,6, 10,11,12, 13,14,15, \n",
    "#                 21,22,23, 27,28,29, 30,31,32, \n",
    "#                 38,39,40, 44,45,46, 47,48,49\n",
    "#             ] \n",
    "\n",
    "#     scaler = MinMaxScaler()\n",
    "#     # scaler = StandardScaler()\n",
    "\n",
    "#     for uid in np.arange(1,10):\n",
    "#         path = '../../../../../PAMAP2_Dataset/Protocol/subject10' + str(uid) + '.dat'\n",
    "#         df = pd.read_table(path, sep=' ', header=None)\n",
    "#         act_imu_filter = df.iloc[:, imu_locs] \n",
    "\n",
    "#         for act_id in range(len(args.act_list)):\n",
    "#             act_filter =  act_imu_filter[df.iloc[:, 1] == args.act_list[act_id]]\n",
    "#             act_data = act_filter.to_numpy()\n",
    "                \n",
    "#             act_data = np.transpose(act_data)\n",
    "#             # sliding window segmentation\n",
    "#             start_idx = 0\n",
    "#             while start_idx + args.window_len < act_data.shape[1]:\n",
    "#                 window_data = act_data[:, start_idx:start_idx+args.window_len]\n",
    "#                 downsamp_data = window_data[:, ::3] # downsample from 100hz to 33.3hz\n",
    "#                 downsamp_data = np.nan_to_num(downsamp_data) # remove nan\n",
    "\n",
    "#                 X.append(downsamp_data)\n",
    "#                 user_labels.append(uid)\n",
    "#                 act_labels.append(act_id)\n",
    "#                 start_idx = start_idx + args.stride_len\n",
    "\n",
    "#     X_n = np.array(X).astype('float32')\n",
    "\n",
    "#     normalized_X = np.zeros_like(X_n) # allocate numpy array for normalized data\n",
    "#     for ch_id in range(X_n.shape[1]): # loop the 27 sensor channels\n",
    "#         ch_data = X_n[:, ch_id, :] # the data of channel id\n",
    "#         scaler = MinMaxScaler() # maybe different scalers?\n",
    "#         ch_data = scaler.fit_transform(ch_data) # scale the data in this channel to [0,1]\n",
    "#         normalized_X[:, ch_id, :] = ch_data # assign normalized data to normalized_X\n",
    "#     #normalized_X = np.transpose(normalized_X, (0, 2, 1)) # I overwrote X here, changed dimensions into: num_samples, sequence_length, feature_length\n",
    "\n",
    "#     normalized_X= normalized_X.reshape(normalized_X.shape[0], 1, normalized_X.shape[1], normalized_X.shape[2]) # convert list to numpy array\n",
    "#     act_labels = np.array(act_labels).astype('float32')\n",
    "#     act_labels = act_labels.reshape(act_labels.shape[0],1)\n",
    "#     act_labels = to_categorical(act_labels, num_classes=len(args.act_list))\n",
    "\n",
    "#     return normalized_X, act_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ecffb-809d-4046-af55-abbf644a4acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab6becd-47e6-421e-bba3-cda623ab8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sliding_window import sliding_window\n",
    "import pickle as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d94cc3e-daa5-44e8-946c-cd272e0f6b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Sensor Channels used in the OPPORTUNITY dataset.\n",
    "NB_SENSOR_CHANNELS = 113\n",
    "\n",
    "# Number of classes in which data is classified (or to be classified).\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# Length of the sliding window used to segmenting the time-series-data.\n",
    "SLIDING_WINDOW_LENGTH = 24\n",
    "\n",
    "# Steps of the sliding window used in segmenting the data.\n",
    "SLIDING_WINDOW_STEP = 12\n",
    "\n",
    "act_labels_txt = ['std', 'wlk', 'sit', 'lie', 'null']\n",
    "\n",
    "# Variable for Batch Size.\n",
    "# BATCH_SIZE = 100\n",
    "\n",
    "# Number filters used in convolutional layers.\n",
    "# NUM_FILTERS = 64\n",
    "\n",
    "# Size of filters used in convolutional layers.\n",
    "# FILTER_SIZE = 5\n",
    "\n",
    "# Units in the long short-term recurrent layers.\n",
    "# NUM_UNITS_LSTM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b02a0539-bb80-4c7b-a3e1-0b1cf676098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      " ..from file ../../../../../data/oppChallenge_gestures.data\n",
      " ..reading instances: train (557963, 113), test (118750, 113)\n",
      " ..after sliding window (testing): inputs (9894, 24, 113), targets (9894,)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = open(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading Data...\")\n",
    "X_train, y_train, X_test, y_test = load_dataset('../../../../../data/oppChallenge_gestures.data')\n",
    "\n",
    "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
    "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))\n",
    "X_test = np.transpose(X_test, (0, 2, 1))\n",
    "X_test= X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2]) # convert list to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c68ed9-f264-4861-8477-8b9cdf568138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ..after sliding window (training): inputs (46495, 24, 113), targets (46495,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(46495, 1, 113, 24)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "print(\" ..after sliding window (training): inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
    "X_train = X_train.reshape((-1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))\n",
    "X_train = np.transpose(X_train, (0, 2, 1))\n",
    "X_train= X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2]) # convert list to numpy array\n",
    "\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9816fa5-ad8a-4893-b17a-3a4802e6989a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94895, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(94895, 1, 27, 171)\n",
    "(94895, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "133923cb-6699-4f45-931d-cd4dfdf8391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc0ae9-e771-4009-8444-faaa0a51471b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59be9937-93da-4ebb-9d21-fde161b3ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(args, X_train, X_test, y_train, y_test):\n",
    "    trainDataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "    testDataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "    # Train/Test dataset split\n",
    "    # train_size = int(args.train_split * len(dataset))\n",
    "    # test_size = len(dataset) - train_size\n",
    "    # # trainDataset, testDataset = torch.Tensor(dataset[:train_size]), torch.Tensor(dataset[train_size:])\n",
    "    # trainDataset, testDataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # trainDataset2, testDataset2 = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    trainLoader = torch.utils.data.DataLoader(trainDataset,\n",
    "        batch_size=args.batchSize, shuffle=True) \n",
    "\n",
    "    testLoader = torch.utils.data.DataLoader(testDataset,\n",
    "        batch_size=args.batchSize, shuffle=False)\n",
    "    return trainLoader, testLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ea619-7d28-4205-95da-2e99e25fce11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e1f5a-7280-4575-ab05-bb14a3af6a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ea2fd-6eae-49a0-96cb-98165774d12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3f139-ed98-4fff-b723-63f2bb9608fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38fab823-f472-4620-bf9e-29e8ba54a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dae(args, exDir, trainLoader, testLoader):\n",
    "    dae = DAE(nz=args.nz, imSize=args.imSize, fSize=args.fSize, sigma=args.sigma, multimodalZ=args.multimodalZ) #sigma=level of corruption\n",
    "    # dis, NZ = build_dis(args, dae=dae, multimodalZ=args.multimodalZ)\n",
    "    \n",
    "    if dae.useCUDA:\n",
    "        torch.cuda.set_device(args.gpuNo)\n",
    "        # torch.cuda.set_device(args.gpuNo)\n",
    "        dae.cuda()\n",
    "        # dis.cuda()\n",
    "    \n",
    "    save_input_args(exDir, args)  #save training opts\n",
    "    save_exp_details(args, exDir)\n",
    "\n",
    "    # #Create optimizers\n",
    "    optimDAE = optim.RMSprop(dae.parameters(), lr = args.lr, momentum=args.momentum)\n",
    "    # optimDIS = optim.RMSprop(dis.parameters(), lr = args.lr, momentum=args.momentum)\n",
    "\n",
    "    # optimDAE = optim.Adam(dae.parameters(), lr = args.lr)\n",
    "    # optimDIS = optim.Adam(dis.parameters(), lr = args.lr)    \n",
    "    \n",
    "    # #Keeping track of training\n",
    "    losses = {'enc': [], 'rec': [], 'dis':[], 'test rec':[]}\n",
    "\n",
    "    # xTest, yTest = prep_data(iter(testLoader).next(), useCUDA=dae.useCUDA)\n",
    "\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "        for e in range(args.maxEpochs):\n",
    "\n",
    "            epochEncLoss=0\n",
    "            epochRecLoss=0\n",
    "            epochDisLoss=0\n",
    "            epochKlLoss=0\n",
    "\n",
    "            for i, data in enumerate(trainLoader):\n",
    "                # print(i)\n",
    "\n",
    "                T = time()\n",
    "\n",
    "                dae.train()\n",
    "                # dis.train()\n",
    "\n",
    "                x, y = prep_data(data, useCUDA=dae.useCUDA)\n",
    "                # print(x.shape)\n",
    "            \n",
    "                # get outputs\n",
    "                zFake, xRec = dae.forward(x)\n",
    "\n",
    "                # clac losses\n",
    "                recLoss = dae.rec_loss(xRec, x, loss=args.loss)  #loss='BCE' or 'MSE'\n",
    "                # klLoss = dae.kl_loss(z_m, z_l)\n",
    "                # loss = recLoss + 0.1*klLoss\n",
    "                \n",
    "            \n",
    "                optimDAE.zero_grad()\n",
    "                # loss.backward()\n",
    "                recLoss.backward()\n",
    "                optimDAE.step()            \n",
    "            \n",
    "                # zFake, xRec = dae.forward(x)    \n",
    "            \n",
    "                # disLoss = dis.dis_loss(zFake)\n",
    "                #do updates\n",
    "\n",
    "                # optimDIS.zero_grad()\n",
    "                # disLoss.backward()\n",
    "                # optimDIS.step()\n",
    "            \n",
    "                # encLoss = dis.gen_loss(zFake)\n",
    "            \n",
    "                # optimDAE.zero_grad()\n",
    "                # encLoss.backward()\n",
    "                # optimDAE.step()                   \n",
    "\n",
    "\n",
    "                # epochEncLoss+=encLoss.detach().cpu().numpy()\n",
    "                epochRecLoss+=recLoss.detach().cpu().numpy()\n",
    "                # epochKlLoss+=klLoss.detach().cpu().numpy()\n",
    "                # epochDisLoss+=disLoss.detach().cpu().numpy()\n",
    "            \n",
    "                if i%100 == 0:\n",
    "                    print('[%d, %d] rec: %0.5f, time: %0.3f' % (e, i, recLoss.detach().cpu().numpy(), time() - T))\n",
    "                    # print('[%d, %d] rec: %0.5f, kl: %0.5f, time: %0.3f' % (e, i, recLoss.detach().cpu().numpy(), klLoss.detach().cpu().numpy(), time() - T))\n",
    "                    \n",
    "\n",
    "            # storing losses for plotting later\n",
    "            # losses['enc'].append(epochEncLoss/i)\n",
    "            losses['rec'].append(epochRecLoss/i)\n",
    "            # losses['dis'].append(epochDisLoss/i)\n",
    "\n",
    "            #### Test\n",
    "            dae.eval()\n",
    "            # dis.eval()\n",
    "\n",
    "            # #get test outuputs and losses\n",
    "            # xTest, yTest = prep_data(iter(testLoader).next(), useCUDA=dae.useCUDA)\n",
    "            # zTest, recTest = dae.forward(xTest)  #N.B. corruption in here\n",
    "            # recLossTest = dae.rec_loss(recTest, xTest)\n",
    "            # # klLossTest = dae.kl_loss(z_m_test, z_l_test)\n",
    "            # #Plot losses\n",
    "            # # losses['test rec'].append(recLossTest.data[0])\n",
    "            # losses['test rec'].append(recLossTest.detach().cpu().numpy())\n",
    "\n",
    "            # if e > 0: #only one point for test rec otherwise\n",
    "            #     plot_losses(losses, exDir, epochs=e+1)\n",
    "            #     plot_norm_losses(losses, exDir)\n",
    "\n",
    "            #save parameters\n",
    "            dae.save_params(exDir)\n",
    "            # dis.save_params(exDir)\n",
    "\n",
    "            #Save images of original and rec\n",
    "            # save_image(xTest.data, join(exDir, 'original.png'))\n",
    "            # save_image(recTest.data, join(exDir, 'rec.png'))\n",
    "\n",
    "            #Save samples\n",
    "            # sampleDir = join(exDir,'epoch_'+str(e))\n",
    "            # os.mkdir(sampleDir)\n",
    "            # print('sample dir:', sampleDir)\n",
    "            # dae.sample_x(args.M, sampleDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27de6c49-c3df-4507-81fe-52382824b5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46495, 1, 113, 24)\n",
      "(46495, 5)\n",
      "Outputs will be saved to: data/experiments/DAE_EVAL_Missing/Ex_9\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "args = Args()\n",
    "\n",
    "random.seed(args.random_seed)\n",
    "np.random.seed(args.random_seed)\n",
    "torch.manual_seed(args.random_seed)\n",
    "\n",
    "# X, labels = prepare_data(args)\n",
    "# X = X_train\n",
    "# labels = y_train\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "trainLoader, testLoader = prepare_dataloaders(args, X_train, X_test, y_train, y_test)\n",
    "\n",
    "exDir = make_new_folder(args.outDir)\n",
    "print('Outputs will be saved to:', exDir)\n",
    "\n",
    "\n",
    "#train_activity_recognition(args, exDir, trainLoader, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693183a-cdf1-4a4b-808d-abe886309ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89150e80-1718-4a62-8cd9-e0bcabcf6c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental details:\n",
      "root = ../data\n",
      "batchSize = 64\n",
      "maxEpochs = 100\n",
      "nz = 200\n",
      "lr = 0.0001\n",
      "fSize = 64\n",
      "outDir = data/experiments/DAE_EVAL_Missing\n",
      "commit = eval\n",
      "alpha = 1.0\n",
      "M = 5\n",
      "loss = MSE\n",
      "loadDAE = False\n",
      "loadSVM = False\n",
      "load_DAE_from = None\n",
      "evalMode = False\n",
      "comment = \n",
      "momentum = 0.1\n",
      "c = 0.01\n",
      "svmLR = 0.0001\n",
      "Ntest = 100\n",
      "gpuNo = 2\n",
      "cuda_id = 2\n",
      "multimodalZ = False\n",
      "window_len = 512\n",
      "stride_len = 20\n",
      "act_list = [1, 2, 3, 4, 5, 6, 7, 12, 13, 16, 17, 24]\n",
      "imSize = 64\n",
      "sigma = [8, 10]\n",
      "random_seed = 2\n",
      "train_split = 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xyang18/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] rec: 0.01394, time: 1.015\n",
      "[0, 100] rec: 0.00827, time: 0.305\n",
      "[0, 200] rec: 0.00788, time: 0.322\n",
      "[0, 300] rec: 0.00818, time: 0.301\n",
      "[0, 400] rec: 0.00824, time: 0.311\n",
      "[0, 500] rec: 0.00812, time: 0.435\n",
      "[0, 600] rec: 0.00780, time: 0.331\n",
      "[0, 700] rec: 0.00573, time: 0.470\n",
      "saving params...\n",
      "[1, 0] rec: 0.00469, time: 0.422\n",
      "[1, 100] rec: 0.00486, time: 0.316\n",
      "[1, 200] rec: 0.00397, time: 0.349\n",
      "[1, 300] rec: 0.00395, time: 0.308\n",
      "[1, 400] rec: 0.00387, time: 0.338\n",
      "[1, 500] rec: 0.00366, time: 0.304\n",
      "[1, 600] rec: 0.00369, time: 0.415\n",
      "[1, 700] rec: 0.00312, time: 0.343\n",
      "saving params...\n",
      "[2, 0] rec: 0.00304, time: 0.374\n",
      "[2, 100] rec: 0.00316, time: 0.336\n",
      "[2, 200] rec: 0.00309, time: 0.310\n",
      "[2, 300] rec: 0.00286, time: 0.319\n",
      "[2, 400] rec: 0.00295, time: 0.301\n",
      "[2, 500] rec: 0.00289, time: 0.348\n",
      "[2, 600] rec: 0.00235, time: 0.372\n",
      "[2, 700] rec: 0.00227, time: 0.336\n",
      "saving params...\n",
      "[3, 0] rec: 0.00281, time: 0.413\n",
      "[3, 100] rec: 0.00266, time: 0.301\n",
      "[3, 200] rec: 0.00274, time: 0.431\n",
      "[3, 300] rec: 0.00228, time: 0.359\n",
      "[3, 400] rec: 0.00280, time: 0.315\n",
      "[3, 500] rec: 0.00194, time: 0.305\n",
      "[3, 600] rec: 0.00191, time: 0.333\n",
      "[3, 700] rec: 0.00205, time: 0.331\n",
      "saving params...\n",
      "[4, 0] rec: 0.00204, time: 0.337\n",
      "[4, 100] rec: 0.00198, time: 0.337\n",
      "[4, 200] rec: 0.00221, time: 0.300\n",
      "[4, 300] rec: 0.00173, time: 0.433\n",
      "[4, 400] rec: 0.00200, time: 0.305\n",
      "[4, 500] rec: 0.00215, time: 0.310\n",
      "[4, 600] rec: 0.00182, time: 0.336\n",
      "[4, 700] rec: 0.00202, time: 0.346\n",
      "saving params...\n",
      "[5, 0] rec: 0.00180, time: 0.401\n",
      "[5, 100] rec: 0.00142, time: 0.318\n",
      "[5, 200] rec: 0.00147, time: 0.308\n",
      "[5, 300] rec: 0.00169, time: 0.300\n",
      "[5, 400] rec: 0.00144, time: 0.315\n",
      "[5, 500] rec: 0.00180, time: 0.311\n",
      "[5, 600] rec: 0.00130, time: 0.321\n",
      "[5, 700] rec: 0.00145, time: 0.303\n",
      "saving params...\n",
      "[6, 0] rec: 0.00159, time: 0.398\n",
      "[6, 100] rec: 0.00168, time: 0.311\n",
      "[6, 200] rec: 0.00134, time: 0.314\n",
      "[6, 300] rec: 0.00181, time: 0.396\n",
      "[6, 400] rec: 0.00152, time: 0.300\n",
      "[6, 500] rec: 0.00157, time: 0.421\n",
      "[6, 600] rec: 0.00146, time: 0.310\n",
      "[6, 700] rec: 0.00132, time: 0.383\n",
      "saving params...\n",
      "[7, 0] rec: 0.00145, time: 0.365\n",
      "[7, 100] rec: 0.00147, time: 0.330\n",
      "[7, 200] rec: 0.00186, time: 0.435\n",
      "[7, 300] rec: 0.00137, time: 0.314\n",
      "[7, 400] rec: 0.00126, time: 0.298\n",
      "[7, 500] rec: 0.00143, time: 0.302\n",
      "[7, 600] rec: 0.00104, time: 0.309\n",
      "[7, 700] rec: 0.00132, time: 0.421\n",
      "saving params...\n",
      "[8, 0] rec: 0.00120, time: 0.313\n",
      "[8, 100] rec: 0.00120, time: 0.310\n",
      "[8, 200] rec: 0.00132, time: 0.315\n",
      "[8, 300] rec: 0.00124, time: 0.338\n",
      "[8, 400] rec: 0.00135, time: 0.317\n",
      "[8, 500] rec: 0.00125, time: 0.317\n",
      "[8, 600] rec: 0.00134, time: 0.292\n",
      "[8, 700] rec: 0.00136, time: 0.307\n",
      "saving params...\n",
      "[9, 0] rec: 0.00127, time: 0.437\n",
      "[9, 100] rec: 0.00113, time: 0.312\n",
      "[9, 200] rec: 0.00129, time: 0.355\n",
      "[9, 300] rec: 0.00116, time: 0.395\n",
      "[9, 400] rec: 0.00105, time: 0.301\n",
      "[9, 500] rec: 0.00143, time: 0.307\n",
      "[9, 600] rec: 0.00103, time: 0.312\n",
      "[9, 700] rec: 0.00117, time: 0.311\n",
      "saving params...\n",
      "[10, 0] rec: 0.00096, time: 0.343\n",
      "[10, 100] rec: 0.00121, time: 0.296\n",
      "[10, 200] rec: 0.00127, time: 0.324\n",
      "[10, 300] rec: 0.00133, time: 0.456\n",
      "[10, 400] rec: 0.00129, time: 0.312\n",
      "[10, 500] rec: 0.00090, time: 0.299\n",
      "[10, 600] rec: 0.00118, time: 0.330\n",
      "[10, 700] rec: 0.00102, time: 0.372\n",
      "saving params...\n",
      "[11, 0] rec: 0.00109, time: 0.342\n",
      "[11, 100] rec: 0.00118, time: 0.437\n",
      "[11, 200] rec: 0.00099, time: 0.309\n",
      "[11, 300] rec: 0.00117, time: 0.306\n",
      "[11, 400] rec: 0.00112, time: 0.348\n",
      "[11, 500] rec: 0.00111, time: 0.329\n",
      "[11, 600] rec: 0.00112, time: 0.315\n",
      "[11, 700] rec: 0.00098, time: 0.302\n",
      "saving params...\n",
      "[12, 0] rec: 0.00119, time: 0.321\n",
      "[12, 100] rec: 0.00115, time: 0.298\n",
      "[12, 200] rec: 0.00105, time: 0.355\n",
      "[12, 300] rec: 0.00095, time: 0.316\n",
      "[12, 400] rec: 0.00145, time: 0.293\n",
      "[12, 500] rec: 0.00112, time: 0.304\n",
      "[12, 600] rec: 0.00104, time: 0.418\n",
      "[12, 700] rec: 0.00092, time: 0.320\n",
      "saving params...\n",
      "[13, 0] rec: 0.00111, time: 0.458\n",
      "[13, 100] rec: 0.00116, time: 0.309\n",
      "[13, 200] rec: 0.00085, time: 0.305\n",
      "[13, 300] rec: 0.00095, time: 0.309\n",
      "[13, 400] rec: 0.00118, time: 0.321\n",
      "[13, 500] rec: 0.00091, time: 0.334\n",
      "[13, 600] rec: 0.00107, time: 0.331\n",
      "[13, 700] rec: 0.00111, time: 0.342\n",
      "saving params...\n",
      "[14, 0] rec: 0.00090, time: 0.337\n",
      "[14, 100] rec: 0.00105, time: 0.313\n",
      "[14, 200] rec: 0.00098, time: 0.308\n",
      "[14, 300] rec: 0.00089, time: 0.301\n",
      "[14, 400] rec: 0.00089, time: 0.309\n",
      "[14, 500] rec: 0.00102, time: 0.372\n",
      "[14, 600] rec: 0.00089, time: 0.445\n",
      "[14, 700] rec: 0.00114, time: 0.309\n",
      "saving params...\n",
      "[15, 0] rec: 0.00103, time: 0.338\n",
      "[15, 100] rec: 0.00086, time: 0.328\n",
      "[15, 200] rec: 0.00095, time: 0.317\n",
      "[15, 300] rec: 0.00093, time: 0.306\n",
      "[15, 400] rec: 0.00087, time: 0.330\n",
      "[15, 500] rec: 0.00076, time: 0.318\n",
      "[15, 600] rec: 0.00111, time: 0.440\n",
      "[15, 700] rec: 0.00082, time: 0.369\n",
      "saving params...\n",
      "[16, 0] rec: 0.00092, time: 0.358\n",
      "[16, 100] rec: 0.00100, time: 0.305\n",
      "[16, 200] rec: 0.00089, time: 0.338\n",
      "[16, 300] rec: 0.00075, time: 0.441\n",
      "[16, 400] rec: 0.00096, time: 0.315\n",
      "[16, 500] rec: 0.00120, time: 0.329\n",
      "[16, 600] rec: 0.00092, time: 0.312\n",
      "[16, 700] rec: 0.00105, time: 0.331\n",
      "saving params...\n",
      "[17, 0] rec: 0.00102, time: 0.388\n",
      "[17, 100] rec: 0.00072, time: 0.363\n",
      "[17, 200] rec: 0.00090, time: 0.324\n",
      "[17, 300] rec: 0.00104, time: 0.335\n",
      "[17, 400] rec: 0.00095, time: 0.417\n",
      "[17, 500] rec: 0.00099, time: 0.352\n",
      "[17, 600] rec: 0.00076, time: 0.335\n",
      "[17, 700] rec: 0.00096, time: 0.338\n",
      "saving params...\n",
      "[18, 0] rec: 0.00122, time: 0.409\n",
      "[18, 100] rec: 0.00083, time: 0.322\n",
      "[18, 200] rec: 0.00092, time: 0.305\n",
      "[18, 300] rec: 0.00094, time: 0.338\n",
      "[18, 400] rec: 0.00095, time: 0.309\n",
      "[18, 500] rec: 0.00097, time: 0.310\n",
      "[18, 600] rec: 0.00091, time: 0.302\n",
      "[18, 700] rec: 0.00096, time: 0.315\n",
      "saving params...\n",
      "[19, 0] rec: 0.00094, time: 0.466\n",
      "[19, 100] rec: 0.00082, time: 0.421\n",
      "[19, 200] rec: 0.00091, time: 0.302\n",
      "[19, 300] rec: 0.00085, time: 0.325\n",
      "[19, 400] rec: 0.00100, time: 0.304\n",
      "[19, 500] rec: 0.00089, time: 0.352\n",
      "[19, 600] rec: 0.00064, time: 0.432\n",
      "[19, 700] rec: 0.00093, time: 0.440\n",
      "saving params...\n",
      "[20, 0] rec: 0.00073, time: 0.373\n",
      "[20, 100] rec: 0.00085, time: 0.313\n",
      "[20, 200] rec: 0.00078, time: 0.417\n",
      "[20, 300] rec: 0.00077, time: 0.431\n",
      "[20, 400] rec: 0.00087, time: 0.305\n",
      "[20, 500] rec: 0.00085, time: 0.308\n",
      "[20, 600] rec: 0.00090, time: 0.414\n",
      "[20, 700] rec: 0.00083, time: 0.310\n",
      "saving params...\n",
      "[21, 0] rec: 0.00090, time: 0.507\n",
      "[21, 100] rec: 0.00090, time: 0.436\n",
      "[21, 200] rec: 0.00082, time: 0.424\n",
      "[21, 300] rec: 0.00090, time: 0.377\n",
      "[21, 400] rec: 0.00090, time: 0.303\n",
      "[21, 500] rec: 0.00091, time: 0.300\n",
      "[21, 600] rec: 0.00103, time: 0.320\n",
      "[21, 700] rec: 0.00103, time: 0.393\n",
      "saving params...\n",
      "[22, 0] rec: 0.00084, time: 0.362\n",
      "[22, 100] rec: 0.00093, time: 0.300\n",
      "[22, 200] rec: 0.00080, time: 0.288\n",
      "[22, 300] rec: 0.00077, time: 0.311\n",
      "[22, 400] rec: 0.00094, time: 0.330\n",
      "[22, 500] rec: 0.00069, time: 0.332\n",
      "[22, 600] rec: 0.00081, time: 0.306\n",
      "[22, 700] rec: 0.00082, time: 0.343\n",
      "saving params...\n",
      "[23, 0] rec: 0.00077, time: 0.439\n",
      "[23, 100] rec: 0.00067, time: 0.321\n",
      "[23, 200] rec: 0.00085, time: 0.342\n",
      "[23, 300] rec: 0.00084, time: 0.308\n",
      "[23, 400] rec: 0.00080, time: 0.304\n",
      "[23, 500] rec: 0.00087, time: 0.363\n",
      "[23, 600] rec: 0.00107, time: 0.348\n",
      "[23, 700] rec: 0.00095, time: 0.305\n",
      "saving params...\n",
      "[24, 0] rec: 0.00075, time: 0.445\n",
      "[24, 100] rec: 0.00081, time: 0.298\n",
      "[24, 200] rec: 0.00070, time: 0.326\n",
      "[24, 300] rec: 0.00066, time: 0.328\n",
      "[24, 400] rec: 0.00087, time: 0.315\n",
      "[24, 500] rec: 0.00075, time: 0.310\n",
      "[24, 600] rec: 0.00087, time: 0.308\n",
      "[24, 700] rec: 0.00079, time: 0.309\n",
      "saving params...\n",
      "[25, 0] rec: 0.00074, time: 0.519\n",
      "[25, 100] rec: 0.00102, time: 0.453\n",
      "[25, 200] rec: 0.00068, time: 0.431\n",
      "[25, 300] rec: 0.00073, time: 0.306\n",
      "[25, 400] rec: 0.00067, time: 0.309\n",
      "[25, 500] rec: 0.00072, time: 0.320\n",
      "[25, 600] rec: 0.00081, time: 0.439\n",
      "[25, 700] rec: 0.00057, time: 0.302\n",
      "saving params...\n",
      "[26, 0] rec: 0.00103, time: 0.427\n",
      "[26, 100] rec: 0.00081, time: 0.304\n",
      "[26, 200] rec: 0.00086, time: 0.298\n",
      "[26, 300] rec: 0.00062, time: 0.313\n",
      "[26, 400] rec: 0.00099, time: 0.315\n",
      "[26, 500] rec: 0.00089, time: 0.317\n",
      "[26, 600] rec: 0.00075, time: 0.322\n",
      "[26, 700] rec: 0.00078, time: 0.383\n",
      "saving params...\n",
      "[27, 0] rec: 0.00083, time: 0.318\n",
      "[27, 100] rec: 0.00077, time: 0.340\n",
      "[27, 200] rec: 0.00083, time: 0.306\n",
      "[27, 300] rec: 0.00074, time: 0.328\n",
      "[27, 400] rec: 0.00074, time: 0.295\n",
      "[27, 500] rec: 0.00077, time: 0.315\n",
      "[27, 600] rec: 0.00082, time: 0.307\n",
      "[27, 700] rec: 0.00092, time: 0.425\n",
      "saving params...\n",
      "[28, 0] rec: 0.00068, time: 0.460\n",
      "[28, 100] rec: 0.00073, time: 0.374\n",
      "[28, 200] rec: 0.00088, time: 0.310\n",
      "[28, 300] rec: 0.00081, time: 0.320\n",
      "[28, 400] rec: 0.00072, time: 0.313\n",
      "[28, 500] rec: 0.00067, time: 0.329\n",
      "[28, 600] rec: 0.00075, time: 0.331\n",
      "[28, 700] rec: 0.00076, time: 0.332\n",
      "saving params...\n",
      "[29, 0] rec: 0.00085, time: 0.334\n",
      "[29, 100] rec: 0.00079, time: 0.307\n",
      "[29, 200] rec: 0.00099, time: 0.330\n",
      "[29, 300] rec: 0.00085, time: 0.326\n",
      "[29, 400] rec: 0.00081, time: 0.424\n",
      "[29, 500] rec: 0.00100, time: 0.310\n",
      "[29, 600] rec: 0.00058, time: 0.308\n",
      "[29, 700] rec: 0.00068, time: 0.332\n",
      "saving params...\n",
      "[30, 0] rec: 0.00077, time: 0.464\n",
      "[30, 100] rec: 0.00080, time: 0.315\n",
      "[30, 200] rec: 0.00067, time: 0.313\n",
      "[30, 300] rec: 0.00067, time: 0.386\n",
      "[30, 400] rec: 0.00064, time: 0.297\n",
      "[30, 500] rec: 0.00047, time: 0.306\n",
      "[30, 600] rec: 0.00073, time: 0.308\n",
      "[30, 700] rec: 0.00078, time: 0.325\n",
      "saving params...\n",
      "[31, 0] rec: 0.00069, time: 0.380\n",
      "[31, 100] rec: 0.00086, time: 0.402\n",
      "[31, 200] rec: 0.00057, time: 0.386\n",
      "[31, 300] rec: 0.00074, time: 0.306\n",
      "[31, 400] rec: 0.00078, time: 0.336\n",
      "[31, 500] rec: 0.00067, time: 0.306\n",
      "[31, 600] rec: 0.00075, time: 0.319\n",
      "[31, 700] rec: 0.00076, time: 0.316\n",
      "saving params...\n",
      "[32, 0] rec: 0.00059, time: 0.355\n",
      "[32, 100] rec: 0.00075, time: 0.358\n",
      "[32, 200] rec: 0.00075, time: 0.298\n",
      "[32, 300] rec: 0.00067, time: 0.307\n",
      "[32, 400] rec: 0.00057, time: 0.308\n",
      "[32, 500] rec: 0.00056, time: 0.327\n",
      "[32, 600] rec: 0.00055, time: 0.329\n",
      "[32, 700] rec: 0.00067, time: 0.343\n",
      "saving params...\n",
      "[33, 0] rec: 0.00073, time: 0.353\n",
      "[33, 100] rec: 0.00067, time: 0.337\n",
      "[33, 200] rec: 0.00066, time: 0.310\n",
      "[33, 300] rec: 0.00075, time: 0.424\n",
      "[33, 400] rec: 0.00060, time: 0.348\n",
      "[33, 500] rec: 0.00093, time: 0.383\n",
      "[33, 600] rec: 0.00071, time: 0.342\n",
      "[33, 700] rec: 0.00079, time: 0.337\n",
      "saving params...\n",
      "[34, 0] rec: 0.00079, time: 0.400\n",
      "[34, 100] rec: 0.00068, time: 0.406\n",
      "[34, 200] rec: 0.00078, time: 0.442\n",
      "[34, 300] rec: 0.00065, time: 0.351\n",
      "[34, 400] rec: 0.00052, time: 0.320\n",
      "[34, 500] rec: 0.00062, time: 0.356\n",
      "[34, 600] rec: 0.00095, time: 0.333\n",
      "[34, 700] rec: 0.00055, time: 0.346\n",
      "saving params...\n",
      "[35, 0] rec: 0.00053, time: 0.400\n",
      "[35, 100] rec: 0.00064, time: 0.320\n",
      "[35, 200] rec: 0.00078, time: 0.331\n",
      "[35, 300] rec: 0.00077, time: 0.325\n",
      "[35, 400] rec: 0.00073, time: 0.331\n",
      "[35, 500] rec: 0.00073, time: 0.325\n",
      "[35, 600] rec: 0.00076, time: 0.334\n",
      "[35, 700] rec: 0.00070, time: 0.477\n",
      "saving params...\n",
      "[36, 0] rec: 0.00073, time: 0.464\n",
      "[36, 100] rec: 0.00075, time: 0.332\n",
      "[36, 200] rec: 0.00071, time: 0.333\n",
      "[36, 300] rec: 0.00059, time: 0.329\n",
      "[36, 400] rec: 0.00082, time: 0.313\n",
      "[36, 500] rec: 0.00078, time: 0.335\n"
     ]
    }
   ],
   "source": [
    "train_dae(args, exDir, trainLoader, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc856f48-e36b-4cb7-b4dc-52f8f8c9d25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea9137-179b-4265-96bc-d93ed139040e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d4bdb2-3703-419d-9138-1c76d304a850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97bdfef-a87f-46e3-b1db-9c3e7bb4b0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
